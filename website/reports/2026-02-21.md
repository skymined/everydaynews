# IMDIGEST - 2026-02-21

- ê¸°ì¤€ì¼(KST): 2026-02-20 00:00:00 ~ 23:59:59

## AI News

### OpenAI Newsì—ì„œ 'Our First Proof submissions' ê´€ë ¨ ë°œí‘œ
  - ë¬´ìŠ¨ ë‚´ìš©?
    - We share our AI modelâ€™s proof attempts for the First Proof math challenge, testing research-grade reasoning on expert-level problems.
  - ì™œ íŠ¸ë Œë“œì¸ê°€?
    - í•´ë‹¹ ë°œí‘œëŠ” AI ì œí’ˆ/ì—°êµ¬/ì •ì±… íë¦„ì„ ë³´ì—¬ì£¼ë©° í›„ì† ë°œí‘œì™€ ë¹„êµ ê°€ì¹˜ê°€ ìˆìŠµë‹ˆë‹¤.
  - í‚¤ì›Œë“œ: #our #first #proof #submissions
  - ë§í¬: https://openai.com/index/first-proof-submissions

### Hugging Face Blogì—ì„œ 'GGML and llama.cpp join HF to ensure the long-term progress of Local AI' ê´€ë ¨ ë°œí‘œ
  - ë¬´ìŠ¨ ë‚´ìš©?
    - We are super happy to announce that GGML, creators of Llama.cpp, are joining HF in order to keep future AI open.
    - ğŸ”¥ Georgi Gerganov and team are joining HF with the goal of scaling and supporting the community behind ggml and llama.cpp as Local AI continues to make exponential progre
    - We've been working with Georgi and team for quite some time (we even have awesome core contributors to llama.cpp like Son and Alek in the team already) so this has been a
    - llama.cpp is the fundamental building block for local inference, and transformers is the fundamental building block for model definition, so this is basically a match mad
  - ì™œ íŠ¸ë Œë“œì¸ê°€?
    - í•´ë‹¹ ë°œí‘œëŠ” AI ì œí’ˆ/ì—°êµ¬/ì •ì±… íë¦„ì„ ë³´ì—¬ì£¼ë©° í›„ì† ë°œí‘œì™€ ë¹„êµ ê°€ì¹˜ê°€ ìˆìŠµë‹ˆë‹¤.
  - í‚¤ì›Œë“œ: #ggml #and #llama #cpp #join #ensure
  - ë§í¬: https://huggingface.co/blog/ggml-joins-hf

### Hugging Face Blogì—ì„œ 'Train AI models with Unsloth and Hugging Face Jobs for FREE' ê´€ë ¨ ë°œí‘œ
  - ë¬´ìŠ¨ ë‚´ìš©?
    - This blog post covers how to use Unsloth and Hugging Face Jobs for fast LLM fine-tuning (specifically LiquidAI/LFM2.5-1.2B-Instruct ) through coding agents like Claude Co
    - Unsloth provides ~2x faster training and ~60% less VRAM usage compared to standard methods, so training small models can cost just a few dollars.
    - Why a small model?
    - Small language models like LFM2.5-1.2B-Instruct are ideal candidates for fine-tuning.
  - ì™œ íŠ¸ë Œë“œì¸ê°€?
    - í•´ë‹¹ ë°œí‘œëŠ” AI ì œí’ˆ/ì—°êµ¬/ì •ì±… íë¦„ì„ ë³´ì—¬ì£¼ë©° í›„ì† ë°œí‘œì™€ ë¹„êµ ê°€ì¹˜ê°€ ìˆìŠµë‹ˆë‹¤.
  - í‚¤ì›Œë“œ: #train #models #with #unsloth #and #hugging
  - ë§í¬: https://huggingface.co/blog/unsloth-jobs

### Google Blog (The Keyword)ì—ì„œ 'Gemini 3.1 Pro: A smarter model for your most complex tasks' ê´€ë ¨ ë°œí‘œ
  - ë¬´ìŠ¨ ë‚´ìš©?
    - Gemini 3.1 Pro: A smarter model for your most complex tasks Last week, we released a major update to Gemini 3 Deep Think to solve modern challenges across science, resear
    - Today, weâ€™re releasing the upgraded core intelligence that makes those breakthroughs possible: Gemini 3.1 Pro.
    - We are shipping 3.1 Pro across our consumer and developer products to bring this progress in intelligence to your everyday applications.
    - Starting today, 3.1 Pro is rolling out: - For developers in preview via the Gemini API in Google AI Studio, Gemini CLI, our agentic development platform Google Antigravit
  - ì™œ íŠ¸ë Œë“œì¸ê°€?
    - í•´ë‹¹ ë°œí‘œëŠ” AI ì œí’ˆ/ì—°êµ¬/ì •ì±… íë¦„ì„ ë³´ì—¬ì£¼ë©° í›„ì† ë°œí‘œì™€ ë¹„êµ ê°€ì¹˜ê°€ ìˆìŠµë‹ˆë‹¤.
  - í‚¤ì›Œë“œ: #gemini #pro #smarter #model #for #your
  - ë§í¬: https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-1-pro

### Hugging Face Blogì—ì„œ 'ã€Œãƒ‡ãƒ¼ã‚¿ä¸è¶³ã€ã®å£ã‚’è¶Šãˆã‚‹ï¼šåˆæˆãƒšãƒ«ã‚½ãƒŠãŒæ—¥æœ¬ã®AIé–‹ç™ºã‚’åŠ é€Ÿ' ê´€ë ¨ ë°œí‘œ
  - ë¬´ìŠ¨ ë‚´ìš©?
    - AI ã¯æ—¥æœ¬ã®çµŒæ¸ˆæˆé•·ã«ãŠã‘ã‚‹æ–°ãŸãªç« ã‚’æãå¯èƒ½æ€§ã‚’ç§˜ã‚ã¦ãŠã‚Šã€ãã®æŠ€è¡“ã«ã‚ˆã£ã¦ 100 å…†å†† (6,500 å„„ç±³ãƒ‰ãƒ«) ã‚’è¶…ãˆã‚‹çµŒæ¸ˆä¾¡å€¤ãŒå‰µå‡ºã•ã‚Œã‚‹ã¨äºˆæ¸¬ã•ã‚Œã¦ã„ã¾ã™ã€‚ã—ã‹ã—ã€ãã®å·¨å¤§ãªãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«ã‚’å®Ÿç¾ã§ãã‚‹ã‹ã©ã†ã‹ã¯ã€å¤šãã®AIãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«æ±ºå®šçš„ã«æ¬ ã‘ã¦ã„ã‚‹â€œã‚ã‚‹1ã¤ã®è¦ç´ â€ã«ã‹ã‹ã£ã¦ã„ã¾ã™ã€‚ãã‚Œã¯ã€å®Ÿå‹™ã§ã€Œä½¿ãˆã‚‹å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã€ã§ã™
  - ì™œ íŠ¸ë Œë“œì¸ê°€?
    - í•´ë‹¹ ë°œí‘œëŠ” AI ì œí’ˆ/ì—°êµ¬/ì •ì±… íë¦„ì„ ë³´ì—¬ì£¼ë©° í›„ì† ë°œí‘œì™€ ë¹„êµ ê°€ì¹˜ê°€ ìˆìŠµë‹ˆë‹¤.
  - í‚¤ì›Œë“œ: #ai #trend #news
  - ë§í¬: https://huggingface.co/blog/nvidia/nemotron-personas-japan-nttdata-ja

### Microsoft Research Blogì—ì„œ 'Media Authenticity Methods in Practice: Capabilities, Limitations, and Directions' ê´€ë ¨ ë°œí‘œ
  - ë¬´ìŠ¨ ë‚´ìš©?
    - Insights from Microsoftâ€™s Media Integrity and Authentication: Status, Directions, and Futures report It has become increasingly difficult to distinguish fact from fiction
    - Resilient, trustworthy technologies can help people determine whether the content they are viewing was captured by a camera or microphoneâ€”or generated or modified by AI t
    - We refer to technologies aimed at helping viewers verify the source and historyâ€”that is, the provenanceâ€”of digital content as media integrity and authentication (MIA) met
    - This technique, driven by the Coalition for Content Provenance and Authenticity (opens in new tab) (C2PA), a standards body dedicated to s
  - ì™œ íŠ¸ë Œë“œì¸ê°€?
    - í•´ë‹¹ ë°œí‘œëŠ” AI ì œí’ˆ/ì—°êµ¬/ì •ì±… íë¦„ì„ ë³´ì—¬ì£¼ë©° í›„ì† ë°œí‘œì™€ ë¹„êµ ê°€ì¹˜ê°€ ìˆìŠµë‹ˆë‹¤.
  - í‚¤ì›Œë“œ: #media #authenticity #methods #practice #capabilities #limitations
  - ë§í¬: https://www.microsoft.com/en-us/research/blog/media-authenticity-methods-in-practice-capabilities-limitations-and-directions

### AWS Machine Learning Blogì—ì„œ 'Build AI workflows on Amazon EKS with Union.ai and Flyte' ê´€ë ¨ ë°œí‘œ
  - ë¬´ìŠ¨ ë‚´ìš©?
    - Build AI workflows on Amazon EKS with Union.ai and Flyte As artificial intelligence and machine learning (AI/ML) workflows grow in scale and complexity, it becomes harder
    - AI projects often struggle to move from pilot to production.
    - AI projects often fail not because models are bad, but because infrastructure and processes are fragmented and brittle, and the original pilot code base is often forced t
    - This makes it difficult for data scientists and engineers to quickly move from laptop to cluster (local development to production deployment) and reproduce the exact resu
  - ì™œ íŠ¸ë Œë“œì¸ê°€?
    - í•´ë‹¹ ë°œí‘œëŠ” AI ì œí’ˆ/ì—°êµ¬/ì •ì±… íë¦„ì„ ë³´ì—¬ì£¼ë©° í›„ì† ë°œí‘œì™€ ë¹„êµ ê°€ì¹˜ê°€ ìˆìŠµë‹ˆë‹¤.
  - í‚¤ì›Œë“œ: #build #workflows #amazon #eks #with #union
  - ë§í¬: https://aws.amazon.com/blogs/machine-learning/build-ai-workflows-on-amazon-eks-with-union-ai-and-flyte

### AWS Machine Learning Blogì—ì„œ 'Amazon Quick now supports key pair authentication to Snowflake data source' ê´€ë ¨ ë°œí‘œ
  - ë¬´ìŠ¨ ë‚´ìš©?
    - Amazon Quick now supports key pair authentication to Snowflake data source Modern enterprises face significant challenges connecting business intelligence platforms to cl
    - Password-based authentication introduces security vulnerabilities, operational friction, and compliance gapsâ€”especially critical as Snowflake is deprecating username pass
    - Amazon Quick Sight (a capability of Amazon Quick) now supports key pair authentication for Snowflake integrations, using asymmetric cryptography where RSA key pairs repla
    - This enhancement addresses a critical need as Snowflake moves toward deprecating password-based authenticati
  - ì™œ íŠ¸ë Œë“œì¸ê°€?
    - í•´ë‹¹ ë°œí‘œëŠ” AI ì œí’ˆ/ì—°êµ¬/ì •ì±… íë¦„ì„ ë³´ì—¬ì£¼ë©° í›„ì† ë°œí‘œì™€ ë¹„êµ ê°€ì¹˜ê°€ ìˆìŠµë‹ˆë‹¤.
  - í‚¤ì›Œë“œ: #amazon #quick #now #supports #key #pair
  - ë§í¬: https://aws.amazon.com/blogs/machine-learning/amazon-quick-suite-now-supports-key-pair-authentication-to-snowflake-data-source

## Papers (Hugging Face Top 10)

### SpargeAttention2: Trainable Sparse Attention via Hybrid Top-k+Top-p Masking and Distillation Fine-Tuning
- í•œ ì¤„ ìš”ì•½: ìƒì„± ëª¨ë¸(diffusion) ì˜ì—­ì—ì„œ ìƒˆ ëª¨ë¸/ë°©ë²•ë¡ ì„ ì œì•ˆí•´ íš¨ìœ¨ê³¼ ì²˜ë¦¬ì†ë„ ê°œì„ ì„ ë…¸ë¦° ì—°êµ¬ì…ë‹ˆë‹¤.
- í•µì‹¬ ì•„ì´ë””ì–´: ë¬¸ì œ ì •ì˜: ìƒì„± ëª¨ë¸(diffusion)ì—ì„œ ê¸°ì¡´ ë°©ë²•ì˜ í•œê³„ë¥¼ ê°œì„ í•˜ë ¤ëŠ” ëª©ì ì´ ìˆìŠµë‹ˆë‹¤. ì ‘ê·¼ ë°©ë²•: ìƒˆ ëª¨ë¸/ë°©ë²•ë¡  ì¤‘ì‹¬ìœ¼ë¡œ í•´ê²° ì „ëµì„ ì œì‹œí•©ë‹ˆë‹¤. ë…¼ë¬¸ ê·¼ê±° 1: SpargeAttention2: Trainable Sparse Attention via Hybrid Top-k+Top-p Masking and Distillation Fine-Tuning A trainable sparse attention method called SpargeAttention2 is pr ë…¼ë¬¸ ê·¼ê±° 2: Many training-free sparse attention methods are effective for accelerating diffusion models.
- í‚¤ì›Œë“œ: #diffusion #attention #spargeattention2 #trainable #sparse #via
- ë§í¬: https://huggingface.co/papers/2602.13515

### Mobile-Agent-v3.5: Multi-platform Fundamental GUI Agents
- í•œ ì¤„ ìš”ì•½: AI ì—ì´ì „íŠ¸ ì˜ì—­ì—ì„œ ìƒˆ ë²¤ì¹˜ë§ˆí¬/í‰ê°€ í”„ë ˆì„ì„ ì œì•ˆí•´ ì •í™•ë„ ì„±ëŠ¥ ê°œì„ ì„ ë…¸ë¦° ì—°êµ¬ì…ë‹ˆë‹¤.
- í•µì‹¬ ì•„ì´ë””ì–´: ë¬¸ì œ ì •ì˜: AI ì—ì´ì „íŠ¸ì—ì„œ ê¸°ì¡´ ë°©ë²•ì˜ í•œê³„ë¥¼ ê°œì„ í•˜ë ¤ëŠ” ëª©ì ì´ ìˆìŠµë‹ˆë‹¤. ì ‘ê·¼ ë°©ë²•: ìƒˆ ë²¤ì¹˜ë§ˆí¬/í‰ê°€ í”„ë ˆì„ ì¤‘ì‹¬ìœ¼ë¡œ í•´ê²° ì „ëµì„ ì œì‹œí•©ë‹ˆë‹¤. ë…¼ë¬¸ ê·¼ê±° 1: Mobile-Agent-v3.5: Multi-platform Fundamental GUI Agents GUI-Owl-1.5 is a multi-platform GUI agent model with multiple sizes that achieves state-of-the-art performance on ë…¼ë¬¸ ê·¼ê±° 2: The paper introduces GUI-Owl-1.5, the latest native GUI agent model that features instruct/thinking variants in multiple sizes (2B/4B/8B/32B/235B) and supports a range of
- í‚¤ì›Œë“œ: #agents #agent #rl #benchmark #memory #mobile-agent-v3
- ë§í¬: https://huggingface.co/papers/2602.16855

### Unified Latents (UL): How to train your latents
- í•œ ì¤„ ìš”ì•½: ìƒì„± ëª¨ë¸(diffusion) ì˜ì—­ì—ì„œ ìƒˆ í”„ë ˆì„ì›Œí¬/ì‹œìŠ¤í…œì„ ì œì•ˆí•´ ì‹¤ì‚¬ìš© ì„±ëŠ¥ ê°œì„ ì„ ë…¸ë¦° ì—°êµ¬ì…ë‹ˆë‹¤.
- í•µì‹¬ ì•„ì´ë””ì–´: ë¬¸ì œ ì •ì˜: ìƒì„± ëª¨ë¸(diffusion)ì—ì„œ ê¸°ì¡´ ë°©ë²•ì˜ í•œê³„ë¥¼ ê°œì„ í•˜ë ¤ëŠ” ëª©ì ì´ ìˆìŠµë‹ˆë‹¤. ì ‘ê·¼ ë°©ë²•: ìƒˆ í”„ë ˆì„ì›Œí¬/ì‹œìŠ¤í…œ ì¤‘ì‹¬ìœ¼ë¡œ í•´ê²° ì „ëµì„ ì œì‹œí•©ë‹ˆë‹¤. ë…¼ë¬¸ ê·¼ê±° 1: Unified Latents (UL): How to train your latents Unified Latents framework learns joint latent representations using diffusion prior regularization and diffusion model dec ë…¼ë¬¸ ê·¼ê±° 2: We present Unified Latents (UL), a framework for learning latent representations that are jointly regularized by a diffusion prior and decoded by a diffusion model.
- í‚¤ì›Œë“œ: #diffusion #unified #latents #how #train #your
- ë§í¬: https://huggingface.co/papers/2602.17270

### "What Are You Doing?": Effects of Intermediate Feedback from Agentic LLM In-Car Assistants During Multi-Step Processing
- í•œ ì¤„ ìš”ì•½: AI ì—ì´ì „íŠ¸ ì˜ì—­ì—ì„œ ìƒˆ í”„ë ˆì„ì›Œí¬/ì‹œìŠ¤í…œì„ ì œì•ˆí•´ ì‹ ë¢°ì„±ê³¼ ì•ˆì •ì„± ê°œì„ ì„ ë…¸ë¦° ì—°êµ¬ì…ë‹ˆë‹¤.
- í•µì‹¬ ì•„ì´ë””ì–´: ë¬¸ì œ ì •ì˜: AI ì—ì´ì „íŠ¸ì—ì„œ ê¸°ì¡´ ë°©ë²•ì˜ í•œê³„ë¥¼ ê°œì„ í•˜ë ¤ëŠ” ëª©ì ì´ ìˆìŠµë‹ˆë‹¤. ì ‘ê·¼ ë°©ë²•: ìƒˆ í”„ë ˆì„ì›Œí¬/ì‹œìŠ¤í…œ ì¤‘ì‹¬ìœ¼ë¡œ í•´ê²° ì „ëµì„ ì œì‹œí•©ë‹ˆë‹¤. ë…¼ë¬¸ ê·¼ê±° 1: "What Are You Doing?": Effects of Intermediate Feedback from Agentic LLM In-Car Assistants During Multi-Step Processing Users prefer adaptive feedback mechanisms in in-ca ë…¼ë¬¸ ê·¼ê±° 2: Agentic AI assistants that autonomously perform multi-step tasks raise open questions for user experience: how should such systems communicate progress and reasoning duri
- í‚¤ì›Œë“œ: #agent #rl #attention #what #you #doing
- ë§í¬: https://huggingface.co/papers/2602.15569

### Arcee Trinity Large Technical Report
- í•œ ì¤„ ìš”ì•½: ëª¨ë¸ ì•„í‚¤í…ì²˜/ê³„ì‚° ìµœì í™” ì˜ì—­ì—ì„œ ìƒˆ ëª¨ë¸/ë°©ë²•ë¡ ì„ ì œì•ˆí•´ íš¨ìœ¨ê³¼ ì²˜ë¦¬ì†ë„ ê°œì„ ì„ ë…¸ë¦° ì—°êµ¬ì…ë‹ˆë‹¤.
- í•µì‹¬ ì•„ì´ë””ì–´: ë¬¸ì œ ì •ì˜: ëª¨ë¸ ì•„í‚¤í…ì²˜/ê³„ì‚° ìµœì í™”ì—ì„œ ê¸°ì¡´ ë°©ë²•ì˜ í•œê³„ë¥¼ ê°œì„ í•˜ë ¤ëŠ” ëª©ì ì´ ìˆìŠµë‹ˆë‹¤. ì ‘ê·¼ ë°©ë²•: ìƒˆ ëª¨ë¸/ë°©ë²•ë¡  ì¤‘ì‹¬ìœ¼ë¡œ í•´ê²° ì „ëµì„ ì œì‹œí•©ë‹ˆë‹¤. ë…¼ë¬¸ ê·¼ê±° 1: Arcee Trinity Large Technical Report Arcee Trinity models are sparse Mixture-of-Experts architectures with varying parameter counts and activation patterns, utilizing adv ë…¼ë¬¸ ê·¼ê±° 2: We present the technical report for Arcee Trinity Large, a sparse Mixture-of-Experts model with 400B total parameters and 13B activated per token.
- í‚¤ì›Œë“œ: #rl #attention #arcee #trinity #large #technical
- ë§í¬: https://huggingface.co/papers/2602.17004

### Calibrate-Then-Act: Cost-Aware Exploration in LLM Agents
- í•œ ì¤„ ìš”ì•½: AI ì—ì´ì „íŠ¸ ì˜ì—­ì—ì„œ ìƒˆ í”„ë ˆì„ì›Œí¬/ì‹œìŠ¤í…œì„ ì œì•ˆí•´ ì‹ ë¢°ì„±ê³¼ ì•ˆì •ì„± ê°œì„ ì„ ë…¸ë¦° ì—°êµ¬ì…ë‹ˆë‹¤.
- í•µì‹¬ ì•„ì´ë””ì–´: ë¬¸ì œ ì •ì˜: AI ì—ì´ì „íŠ¸ì—ì„œ ê¸°ì¡´ ë°©ë²•ì˜ í•œê³„ë¥¼ ê°œì„ í•˜ë ¤ëŠ” ëª©ì ì´ ìˆìŠµë‹ˆë‹¤. ì ‘ê·¼ ë°©ë²•: ìƒˆ í”„ë ˆì„ì›Œí¬/ì‹œìŠ¤í…œ ì¤‘ì‹¬ìœ¼ë¡œ í•´ê²° ì „ëµì„ ì œì‹œí•©ë‹ˆë‹¤. ë…¼ë¬¸ ê·¼ê±° 1: Calibrate-Then-Act: Cost-Aware Exploration in LLM Agents Large language models can be improved for complex tasks by explicitly reasoning about cost-uncertainty tradeoffs  ë…¼ë¬¸ ê·¼ê±° 2: LLMs are increasingly being used for complex problems which are not necessarily resolved in a single response, but require interacting with an environment to acquire info
- í‚¤ì›Œë“œ: #agents #agent #calibrate-then-act #cost-aware #exploration #llm
- ë§í¬: https://huggingface.co/papers/2602.16699

### TactAlign: Human-to-Robot Policy Transfer via Tactile Alignment
- í•œ ì¤„ ìš”ì•½: AI ì—ì´ì „íŠ¸ ì˜ì—­ì—ì„œ ìƒˆ ëª¨ë¸/ë°©ë²•ë¡ ì„ ì œì•ˆí•´ ì¼ë°˜í™” ì„±ëŠ¥ ê°œì„ ì„ ë…¸ë¦° ì—°êµ¬ì…ë‹ˆë‹¤.
- í•µì‹¬ ì•„ì´ë””ì–´: ë¬¸ì œ ì •ì˜: AI ì—ì´ì „íŠ¸ì—ì„œ ê¸°ì¡´ ë°©ë²•ì˜ í•œê³„ë¥¼ ê°œì„ í•˜ë ¤ëŠ” ëª©ì ì´ ìˆìŠµë‹ˆë‹¤. ì ‘ê·¼ ë°©ë²•: ìƒˆ ëª¨ë¸/ë°©ë²•ë¡  ì¤‘ì‹¬ìœ¼ë¡œ í•´ê²° ì „ëµì„ ì œì‹œí•©ë‹ˆë‹¤. ë…¼ë¬¸ ê·¼ê±° 1: TactAlign: Human-to-Robot Policy Transfer via Tactile Alignment TactAlign enables transfer of human tactile demonstrations to robots with different embodiments through cr ë…¼ë¬¸ ê·¼ê±° 2: Human demonstrations collected by wearable devices (e.g., tactile gloves) provide fast and dexterous supervision for policy learning, and are guided by rich, natural tact
- í‚¤ì›Œë“œ: #alignment #policy #tactalign #human-to-robot #transfer #via
- ë§í¬: https://huggingface.co/papers/2602.13579

### DDiT: Dynamic Patch Scheduling for Efficient Diffusion Transformers
- í•œ ì¤„ ìš”ì•½: ìƒì„± ëª¨ë¸(diffusion) ì˜ì—­ì—ì„œ ìƒˆ ì ‘ê·¼ë²•ì„ ì œì•ˆí•´ íš¨ìœ¨ê³¼ ì²˜ë¦¬ì†ë„ ê°œì„ ì„ ë…¸ë¦° ì—°êµ¬ì…ë‹ˆë‹¤.
- í•µì‹¬ ì•„ì´ë””ì–´: ë¬¸ì œ ì •ì˜: ìƒì„± ëª¨ë¸(diffusion)ì—ì„œ ê¸°ì¡´ ë°©ë²•ì˜ í•œê³„ë¥¼ ê°œì„ í•˜ë ¤ëŠ” ëª©ì ì´ ìˆìŠµë‹ˆë‹¤. ì ‘ê·¼ ë°©ë²•: ìƒˆ ì ‘ê·¼ë²• ì¤‘ì‹¬ìœ¼ë¡œ í•´ê²° ì „ëµì„ ì œì‹œí•©ë‹ˆë‹¤. ë…¼ë¬¸ ê·¼ê±° 1: DDiT: Dynamic Patch Scheduling for Efficient Diffusion Transformers Dynamic tokenization improves diffusion transformer efficiency by adjusting patch sizes based on conte ë…¼ë¬¸ ê·¼ê±° 2: Diffusion Transformers (DiTs) have achieved state-of-the-art performance in image and video generation, but their success comes at the cost of heavy computation.
- í‚¤ì›Œë“œ: #diffusion #rl #ddit #dynamic #patch #scheduling
- ë§í¬: https://huggingface.co/papers/2602.16968

### Frontier AI Risk Management Framework in Practice: A Risk Analysis Technical Report v1.5
- í•œ ì¤„ ìš”ì•½: AI ì—ì´ì „íŠ¸ ì˜ì—­ì—ì„œ ìƒˆ í”„ë ˆì„ì›Œí¬/ì‹œìŠ¤í…œì„ ì œì•ˆí•´ ì‹¤ì‚¬ìš© ì„±ëŠ¥ ê°œì„ ì„ ë…¸ë¦° ì—°êµ¬ì…ë‹ˆë‹¤.
- í•µì‹¬ ì•„ì´ë””ì–´: ë¬¸ì œ ì •ì˜: AI ì—ì´ì „íŠ¸ì—ì„œ ê¸°ì¡´ ë°©ë²•ì˜ í•œê³„ë¥¼ ê°œì„ í•˜ë ¤ëŠ” ëª©ì ì´ ìˆìŠµë‹ˆë‹¤. ì ‘ê·¼ ë°©ë²•: ìƒˆ í”„ë ˆì„ì›Œí¬/ì‹œìŠ¤í…œ ì¤‘ì‹¬ìœ¼ë¡œ í•´ê²° ì „ëµì„ ì œì‹œí•©ë‹ˆë‹¤. ë…¼ë¬¸ ê·¼ê±° 1: Frontier AI Risk Management Framework in Practice: A Risk Analysis Technical Report v1.5 Frontier AI risk analysis assesses critical dimensions including cyber offense, p ë…¼ë¬¸ ê·¼ê±° 2: To understand and identify the unprecedented risks posed by rapidly advancing artificial intelligence (AI) models, Frontier AI Risk Management Framework in Practice prese
- í‚¤ì›Œë“œ: #agent #frontier #risk #management #framework #practice
- ë§í¬: https://huggingface.co/papers/2602.14457

### ArXiv-to-Model: A Practical Study of Scientific LM Training
- í•œ ì¤„ ìš”ì•½: AI ëª¨ë¸/ì‹œìŠ¤í…œ ì˜ì—­ì—ì„œ ìƒˆ í”„ë ˆì„ì›Œí¬/ì‹œìŠ¤í…œì„ ì œì•ˆí•´ ì‹¤ì‚¬ìš© ì„±ëŠ¥ ê°œì„ ì„ ë…¸ë¦° ì—°êµ¬ì…ë‹ˆë‹¤.
- í•µì‹¬ ì•„ì´ë””ì–´: ë¬¸ì œ ì •ì˜: AI ëª¨ë¸/ì‹œìŠ¤í…œì—ì„œ ê¸°ì¡´ ë°©ë²•ì˜ í•œê³„ë¥¼ ê°œì„ í•˜ë ¤ëŠ” ëª©ì ì´ ìˆìŠµë‹ˆë‹¤. ì ‘ê·¼ ë°©ë²•: ìƒˆ í”„ë ˆì„ì›Œí¬/ì‹œìŠ¤í…œ ì¤‘ì‹¬ìœ¼ë¡œ í•´ê²° ì „ëµì„ ì œì‹œí•©ë‹ˆë‹¤. ë…¼ë¬¸ ê·¼ê±° 1: ArXiv-to-Model: A Practical Study of Scientific LM Training Training a 1.36B-parameter scientific language model from raw arXiv LaTeX sources demonstrates the impact of p ë…¼ë¬¸ ê·¼ê±° 2: While frontier large language models demonstrate strong reasoning and mathematical capabilities, the practical process of training domain-specialized scientific language 
- í‚¤ì›Œë“œ: #arxiv-to-model #practical #study #scientific #training
- ë§í¬: https://huggingface.co/papers/2602.17288
