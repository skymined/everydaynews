# IMDIGEST - 2026-02-20

- 기준일(KST): 2026-02-19 00:00:00 ~ 23:59:59

## AI News

### 오픈아이가 독립적 인공지능 정렬 연구에 750만 달러를 투자한다
  - 내용 요약
    - 오픈아이는 알인 프로젝트(The Alignment Project)에 750만 달러를 지원하여 독립적인 AI 정렬 연구를 강화한다
    - 이 투자는 글로벌 AGI 안전과 보안 위험을 해결하기 위한 노력에 기여할 예정이다
  - 링크: https://openai.com/index/advancing-independent-research-ai-alignment

### 구글 CEO 푸치아이가 인도 AI 영향력 정상회담에서 AI의 잠재력을 강조
  - 내용 요약
    - 구글은 인도 비자그apatnam에 AI 전용 데이터센터를 건설할 계획을 발표
    - 이 데이터센터는 기계학습과 클라우드 컴퓨팅을 위한 고성능 시스템을 갖추게 될 예정
    - 구글 CEO 푸치아이는 AI가 인류의 가장 큰 플랫폼 전환임을 강조
  - 링크: https://blog.google/company-news/inside-google/message-ceo/sundar-pichai-ai-impact-summit-2026

### Google Blog (The Keyword)에서 'AI Impact Summit 2026' 관련 발표
  - 내용 요약
    - Google Blog (The Keyword)에서 'AI Impact Summit 2026' 관련 내용을 공개했습니다.
    - 공개된 자료를 기준으로 핵심 변경 사항과 영향 범위를 확인할 수 있습니다.
  - 링크: https://blog.google/innovation-and-ai/technology/ai/ai-impact-summit-2026-collection

### 오픈아이가 인도 전역에 AI 접근성 확대
  - 내용 요약
    - 오픈아이는 인도 전역에서 AI 인프라 구축을 시작하여 기업 지원과 일자리 역량 강화를 목표로 한다.
    - 이 서비스는 인도의 기업들이 현지 환경에 맞게 AI 솔루션을 활용할 수 있도록 돕는다.
  - 링크: https://openai.com/index/openai-for-india

### Amazon Bedrock AgentCore를 활용해 통합 인텔리전스 시스템 구축
  - 내용 요약
    - CAKE라는 고객 중심의 챗봇을 Amazon Bedrock AgentCore를 사용하여 개발하였음
    - 다양한 데이터 스토어(Neptune, DynamoDB, OpenSearch Service)와 병렬로 통합된 특화 도구들을 동적 의도 분석과 병렬 실행을 통해 조정함
    - 행사 보안을 위한 행 수준 보안(RLS) 기능 구현 및 고객 인사이트 제공
  - 링크: https://aws.amazon.com/blogs/machine-learning/build-unified-intelligence-with-amazon-bedrock-agentcore

### IBM과 UC 버클리가 IT-Bench와 MAST를 활용해 기업 에이전트 실패 원인 분석
  - 내용 요약
    - IBM 연구소와 UC 버클리는 IT-Bench와 MAST라는 도구를 사용하여, 실세계 IT 자동화에서 LLM 시스템의 실패 사례를 분석했다.
    - 실험에서는 SRE, 보안 및 FinOps 자동화 작업과 관련된 로그/메트릭 쿼리와 Kubernetes 작업을 포함한 다양한 업무를 수행하는 에이전트들의 성능을 평가했다.
    - MAST(Multi-Agent System Failure Taxonomy)를 활용하여 실행 추적 데이터를 구조화된 실패 패턴으로 변환해, 모델별 실패 원인과 해결 방안을 밝혀냈다.
  - 링크: https://huggingface.co/blog/ibm-research/itbenchandmast

### 아마존에서의 AGENT AI 시스템 평가 프레임워크 발표
  - 내용 요약
    - AMAZON은 AGENT AI 시스템 평가 프레임워크를 제시함 (원문 용어: Real-world)
    - 프레임워크는 일반 평가 흐름과 AMAZON Bedrock AgentCore 평가 라이브러리를 포함함
  - 링크: https://aws.amazon.com/blogs/machine-learning/evaluating-ai-agents-real-world-lessons-from-building-agentic-systems-at-amazon

### NVIDIA와 협력한 소재브姆AI는 신경망 모델의 추론 성능을 크게 향상시켰다.
  - 내용 요약
    - Sarvam AI와 NVIDIA는 소재브姆AI의 자주립형 대형 언어 모델(Sovereign 30B)에 대한 추론 성능을 최대 4배 향상시키기 위해 협력하였다. (원문 용어: Hardware-Software, Co-Design)
    - NVIDIA Blackwell 기술과 NVFP4 가중치 양자화를 활용하여 추론 효율성을 높였다.
    - 소재브姆AI는 다양한 언어와 모드를 지원하는 자주립형 대형 언어 모델을 개발하고, 데이터 주권성과 비용 관리를 유지하였다.
  - 링크: https://developer.nvidia.com/blog/how-nvidia-extreme-hardware-software-co-design-delivered-a-large-inference-boost-for-sarvam-ais-sovereign-models

### Gemini 앱이 음악 생성 기능을 추가하여 창의성 표현 방법이 다양해졌습니다.
  - 내용 요약
    - Google DeepMind의 최신 음악 모델 Lyria 3이 Gemini 앱에 도입되어 사용자가 직접 음악을 생성할 수 있게 되었습니다.
    - 사용자는 텍스트나 사진을 업로드하여 고유한 음악 트랙을 만들 수 있으며, 노래 가사와 리듬 등 다양한 요소를 제어할 수 있습니다.
  - 링크: https://blog.google/innovation-and-ai/products/gemini-app/lyria-3

### 프로젝트 사일리카의 유리 저장 기술 발전
  - 내용 요약
    - 새로운 기술이 고급 펄스실리카를 벗어나 식기용 유리를 포함한 보다 저렴하고 일반적인 유리 재료에서도 데이터를 저장할 수 있게 만들었습니다.
    - 페이즈 비올레크 방법은 단일 레이저 패스로 작동하여 복잡성과 비용을 크게 줄였습니다.
    - 병렬 고속 쓰기 기술과 간단한 읽기 기술(하나의 카메라 대신 세 개의 카메라가 필요하지 않음)을 개발하여 제조 과정이 단순화되었습니다.
  - 링크: https://www.microsoft.com/en-us/research/blog/project-silicas-advances-in-glass-storage-technology

### NVIDIA Developer Blog에서 'Unlock Massive Token Throughput with GPU Fractioning in NVIDIA Run:ai' 관련 발표
  - 내용 요약
    - NVIDIA Developer Blog에서 'Unlock Massive Token Throughput with GPU Fractioning in NVIDIA Run:ai' 관련 내용을 공개했습니다.
    - 공개된 자료를 기준으로 핵심 변경 사항과 영향 범위를 확인할 수 있습니다.
  - 링크: https://developer.nvidia.com/blog/unlock-massive-token-throughput-with-gpu-fractioning-in-nvidia-runai

### NVIDIA cuda.compute 라이브러리가 GPU MODE 커널 리더보드에서 최고 성과를 거두어 기술 트렌드에 영향을 미침
  - 내용 요약
    - NVIDIA는 cuda.compute 라이브러리를 통해 Python 개발자들이 고성능 GPU 코드를 작성할 수 있게 했습니다.
    - cuda.compute는 CUB (CUDA Utility Functions)의 고급 기능을 Python API로 쉽게 사용할 수 있도록 합니다.
    - NVIDIA CCCL 팀은 cuda.compute를 활용해 GPU MODE 리더보드에서 가장 높은 성과를 달성했습니다.
  - 링크: https://developer.nvidia.com/blog/topping-the-gpu-mode-kernel-leaderboard-with-nvidia-cuda-compute

## Papers (Hugging Face Top 10)

### SpargeAttention2: Trainable Sparse Attention via Hybrid Top-k+Top-p Masking and Distillation Fine-Tuning
- 한 줄 요약: SpargeAttention2는 하이브리드 Top-k+Top-p 마스킹과 교육 영감을 받은 디스티플레이션 정교화를 통해 고도의 스파르시티를 달성하면서 생성 품질을 유지하는 트레이너블한 스파르시티 어텐션 방법입니다. (원문 용어: Fine-Tuning)
- 핵심 아이디어: SpargeAttention2는 Top-k와 Top-p 마스킹 규칙의 결함을 피하기 위해 하이브리드 마스킹 규칙을 도입하고, 효율적인 트레이너블 스파르시티 어텐션 구현 및 디스티플레이션 정교화 목표를 통해 고도의 스파르시티와 함께 생성 품질을 유지합니다. 실험 결과, 비트레이닝 방식보다 95%의 어텐션 스파르시티와 16.2배의 속도 향상을 달성하면서도 생성 품질이 유지된다는 것을 보여줍니다.
- 키워드: #spargeattention2 #트레이너블-스파르시티-어텐션 #하이브리드-top-k+top-p-마스킹 #디스티플레이션-정교화 #视频扩散模型 #生成质量
- 링크: https://huggingface.co/papers/2602.13515

### Mobile-Agent-v3.5: Multi-platform Fundamental GUI Agents
- 한 줄 요약: GUI-Owl-1.5는 다중 플랫폼 GUI 에이전트 모델로, 다양한 크기와 기능을 지원하며 GUI 자동화, 고정, 도구 호출 등 여러 테스트에서 최상의 성능을 보여줍니다. (원문 용어: Mobile-Agent-v3.5, Multi-platform)
- 핵심 아이디어: GUI-Owl-1.5는 하이브리드 데이터 플라이휠과 통합된 에이전트 능력 강화, 다중 플랫폼 환경 RL 확장을 통해 GUI 자동화, 고정, 도구 호출 등 다양한 GUI 관련 작업에서 최상의 성능을 달성합니다. 이 모델은 시뮬레이션 환경과 클라우드 기반 샌드박스 환경을 결합한 하이브리드 데이터 플라이휠을 사용하여 데이터 수집 효율성을 향상시키고, 통합된 사고 합성 파이프라인을 통해 에이전트 능력을 강화하며, MRPO라는 새로운 환경 RL 알고리즘을 도입하여 다중 플랫폼 환경에서의 문제를 해결합니다.
- 키워드: #gui-owl-1.5 #하이브리드-데이터-플라이휠 #통합된-사고-합성-파이프라인 #mrpo #다중-플랫폼-환경-rl #gui-자동화
- 링크: https://huggingface.co/papers/2602.16855

### Unified Latents (UL): How to train your latents
- 한 줄 요약: Unified Latents(UL)은 디퓨전 프라이오리 정규화와 디퓨전 모델 디코딩을 통해 공동 잠재 표현을 학습하며, Stabl Diffusion 잠재 공간에서 훈련 계산량을 줄여的同时保留原文，翻译为：
- 핵심 아이디어: Unified Latents(UL)은 디퓨전 프라이오리와의 공동 정규화를 통해 잠재 표현을 학습하고, 이를 디퓨전 모델로 디코딩하여 잠재 비트레이트 하한을 제공합니다. 이 방법은 ImageNet-512에서 경쟁력을 갖춘 FID 점수(1.4)와 높은 복원력(PSNR)을 달성하면서, Stabl Diffusion 잠재 공간에서 훈련된 모델보다 적은 훈련 FLOPs를 필요로 합니다. Kinetics-600에서는 새로운 최상의 FVD 점수(1.3)를 설정하였습니다.
- 키워드: #unified-latents #디퓨전-프라이오리 #잠재-표현 #fid #psnr #stable-diffusion
- 링크: https://huggingface.co/papers/2602.17270

### Frontier AI Risk Management Framework in Practice: A Risk Analysis Technical Report v1.5
- 한 줄 요약: Frontier AI Risk Management Framework는 빠르게 발전하는 대형 언어 모델의 위험을 다루기 위해 다섯 가지 중요한 차원에서 위협을 평가하고, 이를 해결하기 위한 강력한 대응 전략을 제시한다.
- 핵심 아이디어: Frontier AI Risk Management Framework는 빠르게 진화하는 대형 언어 모델의 위험성을 다루기 위해 다섯 가지 주요 차원 (사이버 공격, 설득 및 조작, 전략적 속임수, 제어되지 않은 AI 연구 개발, 자아 복제)에서 위협을 평가한다. 이 프레임워크는 새로운 시나리오와 실험을 통해 다양한 위험 요인을 식별하고, 이를 해결하기 위한 구체적인 대응 전략을 제시하며, 안전한 AI 배포를 위한 기초적이고 실용적인 접근 방안을 제공한다.
- 키워드: #frontier-ai-risk-management-framework #대형-언어-모델 #위험-평가 #사이버-공격 #자아-복제
- 링크: https://huggingface.co/papers/2602.14457

### "What Are You Doing?": Effects of Intermediate Feedback from Agentic LLM In-Car Assistants During Multi-Step Processing
- 한 줄 요약: "What Are You Doing?": 연구는 중간 피드백이 주행 등 집중적 상황에서 인공지능 자동차 어시스턴트의 신뢰성과 사용자 경험에 미치는 영향을 조사한다. (원문 용어: In-Car, Multi-Step)
- 핵심 아이디어: 연구는 차량 내 AI 어시스턴트가 복잡한 작업 수행 중 중간 결과 피드백을 제공할 때 사용자의 신뢰와 효율성을 향상시키는 방법을 탐구하였다. 실험에서 중간 피드백은 최종 결과만 제공하는 것보다 사용자 경험과 신뢰를 높이는 데 효과적이었다. 이 연구는 집중적 상황에서 AI 어시스턴트의 적절한 피드백 전략을 설계할 때 고려해야 할 중요한 요소들을 제시하였다.
- 키워드: #llm #in-car-assistant #intermediate-feedback #user-experience #trust #multi-step-processing
- 링크: https://huggingface.co/papers/2602.15569

### Arcee Trinity Large Technical Report
- 한 줄 요약: Arcee Trinity Large는 400B 파라미터의 스 Mixture-of-Experts 모델로, 소프트 클램PED 모멘텀 전문가 편향 업데이트(SMEBU)와 Muon 최적화기를 사용하여 학습되었습니다.
- 핵심 아이디어: Arcee Trinity Large는 다양한 파라미터 수와 활성 패턴을 갖춘 스 Mixture-of-Experts 구조로 구성되어 있으며, interleaved local and global attention, gated attention, depth-scaled sandwich norm 및 sigmoid routing 등의 현대적인 어텐션 메커니즘과 최적화를 사용하여 개발되었습니다. SMEBU는 Trinity Large 모델에서 새로운 MoE 로드 밸런싱 전략으로 소개되었으며, 이 모델들은 모두 zero loss spikes 없이 학습되었습니다.
- 키워드: #arcee-trinity #sparse-mixture-of-experts #muon-optimizer #smebu #interleaved-attention #sigmoid-routing
- 링크: https://huggingface.co/papers/2602.17004

### Calibrate-Then-Act: Cost-Aware Exploration in LLM Agents
- 한 줄 요약: Calibrate-Then-Act(Calibrate-Then-Act) 프레임워크는 대형 언어 모델의 비용 인식 탐색 능력을 향상시킵니다. (원문 용어: Cost-Aware)
- 핵심 아이디어: 대형 언어 모델은 복잡한 문제 해결을 위해 비용 불확실성 균형을 고려해야 합니다. Calibrate-Then-Act 프레임워크는 이러한 비용-불확실성 균형을 명시적으로 처리하여 환경 탐색에서 더 효율적인 결정을 내릴 수 있도록 모델을 강화합니다. 정보 검색 QA와 간단한 코딩 작업 등의 실험 결과에 따르면, CTA는 비용-이익 균형을 명시적으로 제공함으로써 에이전트가 더 우수한 의사결정 전략을 발견할 수 있습니다.
- 키워드: #calibrate-then-act #cost-aware-exploration #llm-agents #sequential-decision-making #information-retrieval #coding
- 링크: https://huggingface.co/papers/2602.16699

### DDiT: Dynamic Patch Scheduling for Efficient Diffusion Transformers
- 한 줄 요약: DDiT는 내용 복잡성과 노이즈 타임스텝에 따라 동적으로 패치 크기를 조정하여 디퓨전 트랜스포머의 효율성을 향상시킵니다.
- 핵심 아이디어: DDiT는 고정된 패치 크기 대신, 이미지와 비디오 생성 과정에서 내용 복잡성과 노이즈 타임스텝에 따라 동적으로 패치 크기를 조절하는 방법을 제시합니다. 이 접근법은 초기 타임스텝에서는 더 큰 패치로 전역 구조를 모델링하고, 나중에는 더 작은 패치로 지역 세부사항을 정교화하여 효율성을 높입니다. 실험 결과, FLUX-1.Dev와 Wan 2.1에서 각각 최대 3.52배와 3.2배의 속도 향상이 이루어졌으며, 생성 질과 명령어 준수는 유지되었습니다.
- 키워드: #ddit #dynamic-patch-scheduling #diffusion-transformers #efficiency #image-generation #video-generation
- 링크: https://huggingface.co/papers/2602.16968

### TactAlign: Human-to-Robot Policy Transfer via Tactile Alignment
- 한 줄 요약: TactAlign는earable 장치로 수집된 인간의 감각 정보를 다른 체제의 로봇으로 전달하는 방법을 제시한다. (원문 용어: Human-to-Robot)
- 핵심 아이디어: TactAlign는 인간과 로봇 간의 체감 정보를 공유된 잠재 공간으로 변환하여 전달하는 방법을 제안한다. 이 방법은 페어드 데이터나 수동 라벨이 필요하지 않으며, 다양한 물체와 작업에 대한 인간의 데이터로도 무조껀적 성능을 보여준다. 이를 통해 로봇에게 인간의 감각 정보를 저비용으로 전달하고, 복잡한 작업에도 적용할 수 있게 한다.
- 키워드: #tactalign #human-to-robot-policy-transfer #tactile-alignment #wearable-devices #latent-representation #cross-embodiment
- 링크: https://huggingface.co/papers/2602.13579

### Computer-Using World Model
- 한 줄 요약: CUWM은 컴퓨터 사용 시나리오에서 현재 상태와 행동을 입력으로 받아 다음 UI 상태를 예측하는 두 단계의 세계 모델입니다. (원문 용어: Computer-Using)
- 핵심 아이디어: CUWM은 복잡한 소프트웨어 환경에서 작업 수행에 도움이 되는 기대 효과를 추론할 수 있도록 설계되었습니다. 이를 위해 CUWM은 먼저 텍스트 설명을 통해 사용자 인터페이스 상태 변화를 예측하고, 그 다음에는 이러한 변화를 시각적으로 합성하여 다음 스크린샷을 생성합니다. 이 연구는 실제 Microsoft Office 애플리케이션에서 수집된 UI 전환 데이터로 훈련되며, 이후 가벼운 강화학습 단계를 통해 텍스트 전환 예측과 컴퓨터 사용 환경의 구조적 요구 사항을 맞춥니다.
- 키워드: #computer-using-world-model #ui-dynamics #two-stage-factorization #textual-description #visual-synthesis #reinforcement-learning
- 링크: https://huggingface.co/papers/2602.17365
